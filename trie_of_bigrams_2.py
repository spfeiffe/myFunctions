from nltk.corpus import brown
import numpy
import os
import sys
from timeit import default_timer as timer

# http://helmer.aksis.uib.no/icame/brown/bcm-los.html
documentId = []
for X in os.listdir("C:\\Users\\spfeiffe\\AppData\\Roaming\\nltk_data\\corpora\\brown\\"):
    if len(X) == 4:
        documentId.append(X)

### begin code generated by Microsoft Copilot

class TrieNode:
    def __init__(self):
        self.children = {}
        self.is_end_of_word = False
        # self.frequency = 0  # Tracks how many times a string ends at this node

class Trie:
    def __init__(self):
        self.root = TrieNode()
    #
    def insert(self, word):
        node = self.root
        for char in word:
            if char not in node.children:
                node.children[char] = TrieNode()
            node = node.children[char]
        node.is_end_of_word = True
        # node.frequency += 1  # Increment frequency when a word is inserted
    #
    def search(self, word):
        node = self.root
        for char in word:
            if char not in node.children:
                return False #, 0
            node = node.children[char]
        return node.is_end_of_word #, node.frequency  # Return whether the word exists and its frequency
    #
    def starts_with(self, prefix):
        node = self.root
        for char in prefix:
            if char not in node.children:
                return False
            node = node.children[char]
        return True

# Example usage
# trie = Trie()
# trie.insert("hello")
# trie.insert("hello")
# trie.insert("world")
# trie.insert("apple")
# trie.insert("apex")
# print(trie.search("hello"))  # Output: (True, 2)
# print(trie.search("world"))  # Output: (True, 1)
# print(trie.search("python"))  # Output: (False, 0)
# print(trie.starts_with("app"))  # True (Prefix exists)

### End of code provided by Microsoft Copilot

bigram_counter = 0
dict_of_docId_and_bigramTF = {}

for thisDocId in documentId:
    print("Beginning " + thisDocId + "...")
    w = [item for item in brown.words(fileids = thisDocId)]
    trie = Trie()
    for i in range(len(w)-1):
        this_bigram = w[i] + " " + w[i+1]
        if not trie.search(this_bigram):
            trie.insert(this_bigram)
            bigram_counter += 1
            k = this_bigram.replace(" ", "_")
            if k not in dict_of_docId_and_bigramTF:
                dict_of_docId_and_bigramTF[k] = {}
                dict_of_docId_and_bigramTF[k]["docId"] = thisDocId
                dict_of_docId_and_bigramTF[k]["TF"] = 1
            else:
                dict_of_docId_and_bigramTF[k]["TF"] += 1

table_of_docId_and_bigramTF = []
for k in dict_of_docId_and_bigramTF:
    table_of_docId_and_bigramTF.append([   k, dict_of_docId_and_bigramTF[k]["docId"], dict_of_docId_and_bigramTF[k]["TF"]   ])

>>> len(table_of_docId_and_bigramTF)
455202
>>> len(table_of_docId_and_bigramTF[0])
3
>>> for X in table_of_docId_and_bigramTF[0]:
...   print(X)
...
The_Fulton
ca01
1
>>>
